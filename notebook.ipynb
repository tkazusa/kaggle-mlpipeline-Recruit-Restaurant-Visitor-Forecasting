{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comprehensive-detector",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Processing を用いた Recruit Restaurant Visitor Forecasting 解法の機械学習パイプライン化\n",
    "\n",
    "このノートブックでは、AWS のマネージドな機械学習基盤サービスである、Amazon SageMaker を活用して、前処理や学習、推論を行います。 特にSageMaker の機能である SageMaker Processing を活用すると、 一般的な Docker コンテナによる機械学習の実行方法から大きく変更することなく、マネージドな機械学習基盤を活用できるので便利です。 今回は Kaggle で行われたレストランの訪問者数を予測する [Recruit Restaurant Visitor Forecasting](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting) コンペを題材に、その解法を AWS を用いて実行するようなパイプラインにする手段を見ていきましょう。今回は Deiscussion にある [8th place solution write-up](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/49166) を参考にしました。解法は solution.ipynb にまとめられていますが、機械学習パイプラインとしての取り回しを良くするために、前処理、ハイパーパラメータの調整、学習と推論のそれぞれのステップに分割しました。詳細は \n",
    "`./scripts` 以下をご確認ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "# SageMaker を活用するための権限が付与された Role を準備します。\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-denmark",
   "metadata": {},
   "source": [
    "## 処理を実行するための Docker イメージを準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./scripts/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t kaggle-reqruit-sagemaker ./scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# boto3の機能を使ってリポジトリ名に必要な情報を取得する\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "tag = ':latest'\n",
    "\n",
    "# Repository 名の中に sagemaker が含まれている必要がある\n",
    "ecr_repository = f'kaggle-reqruit-sagemaker'\n",
    "image_uri = f'{account_id}.dkr.ecr.{region}.amazonaws.com/{ecr_repository+tag}'\n",
    "\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    " \n",
    "# リポジトリの作成\n",
    "# すでにある場合はこのコマンドは必要ない\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    " \n",
    "!docker build -t {ecr_repository} .\n",
    "!docker tag {ecr_repository + tag} $image_uri\n",
    "!docker push $image_uri\n",
    "\n",
    "print(f'コンテナは {image_uri} へ登録されています。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-shield",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3_bucket_path = 's3://' + sagemaker_session.default_bucket()\n",
    "\n",
    "job_name = f'reqruit-pipeline-preprocess'\n",
    "preprocessing_input_s3 = s3_bucket_path + '/reqruit-pipeline/data'\n",
    "preprocessing_output_s3 = s3_bucket_path + '/reqruit-pipeline/preprocessed_data'\n",
    "\n",
    "processing_input_dir = '/opt/ml/processing/input'\n",
    "processing_output_dir = '/opt/ml/processing/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ScriptProcessor(\n",
    "                    base_job_name=job_name,\n",
    "                    image_uri=image_uri,\n",
    "                    command=['python3'],\n",
    "                    role=role,\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.c5.xlarge'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.run(\n",
    "    code='./scripts/preprocess/preprocess.py', # S3 の URI でも可\n",
    "    inputs=[ProcessingInput(source=preprocessing_input_s3, destination=processing_input_dir)],\n",
    "    outputs=[ProcessingOutput(source=processing_output_dir, destination=preprocessing_output_s3)],\n",
    "    arguments=[\n",
    "          '--input_dir',processing_input_dir,\n",
    "          '--output_dir',processing_output_dir\n",
    "              ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-acoustic",
   "metadata": {},
   "source": [
    "## ハイパーパラメータのチューニング\n",
    "解法ではハイパーパラメータは調整済みで、既に固定されていましたが、ビジネス上でこのようなモデルを運用する場合には、都度ハイパラのチューニングを行うことがあるのではないでしょうか。今回は [Optuna](https://github.com/optuna/optuna) を使用して調整することにしました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f'reqruit-pipeline-hpo'\n",
    "hpo_input_s3 = s3_bucket_path + '/reqruit-pipeline/preprocessed_data'\n",
    "hpo_output_s3 = s3_bucket_path + '/reqruit-pipeline/hpo'\n",
    "\n",
    "hpo_input_dir = '/opt/ml/processing/input'\n",
    "hpo_output_dir = '/opt/ml/processing/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ScriptProcessor(\n",
    "                    base_job_name=job_name,\n",
    "                    image_uri=image_uri,\n",
    "                    command=['python3'],\n",
    "                    role=role,\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.c5.2xlarge'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.run(\n",
    "    code='./scripts/hpo/hpo.py', # S3 の URI でも可\n",
    "    inputs=[ProcessingInput(source=hpo_input_s3, destination=hpo_input_dir)],\n",
    "    outputs=[ProcessingOutput(source=hpo_output_dir, destination=hpo_output_s3)],\n",
    "    arguments=[\n",
    "          '--input_dir', hpo_input_dir,\n",
    "          '--output_dir', hpo_output_dir,\n",
    "          '--n_trials', \"1\",\n",
    "              ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-lincoln",
   "metadata": {},
   "source": [
    "## 学習と推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f'reqruit-pipeline-train-predict'\n",
    "train_predict_input_s3 = s3_bucket_path + '/reqruit-pipeline/hpo'\n",
    "train_predict_output_s3 = s3_bucket_path + '/reqruit-pipeline/train_predict'\n",
    "\n",
    "train_predict_input_dir = '/opt/ml/processing/input'\n",
    "train_predict_output_dir = '/opt/ml/processing/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ScriptProcessor(\n",
    "                    base_job_name=job_name,\n",
    "                    image_uri=image_uri,\n",
    "                    command=['python3'],\n",
    "                    role=role,\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.c5.2xlarge'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.run(\n",
    "    code='./scripts/train_predict/train_predict.py', # S3 の URI でも可\n",
    "    inputs=[ProcessingInput(source=train_predict_input_s3, destination=train_predict_input_dir)],\n",
    "    outputs=[ProcessingOutput(source=train_predict_output_dir, destination=train_predict_output_s3)],\n",
    "    arguments=[\n",
    "          '--input_dir', processing_input_dir,\n",
    "          '--output_dir', processing_output_dir\n",
    "              ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-parish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
